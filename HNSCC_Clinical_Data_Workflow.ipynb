{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HNSCC Clinical Data\n",
    "\n",
    "## Download and Parse TCGA Clinical Data Workflow\n",
    "\n",
    "### McWeeney Lab, Oregon Health & Science University\n",
    "\n",
    "** Author: Gabrielle Choonoo (choonoo@ohsu.edu) **\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is the step-by-step workflow for downloading and parsing TCGA Clinical XML files to a tab-deliminated file. \n",
    "\n",
    "Required Files:\n",
    "* Manifest File (.txt)\n",
    "* Clinical Data (folders containing .XML files)\n",
    "* This notebook (HNSCC_Clinical_Data_Workflow.ipynb): [[Download here]](https://raw.githubusercontent.com/gchoonoo/HNSCC_Clinical_Data_Notebook/master/HNSCC_Clinical_Data_Workflow.ipynb)\n",
    "\n",
    "Required python packages:\n",
    "- `xml.etree.ElementTree`\n",
    "- `os`\n",
    "- `csv`\n",
    "\n",
    "**Note: this notebook can also be downloaded as an R and python script (only the code blocks seen below will be included): \n",
    "* [[Download python script here]](https://raw.githubusercontent.com/gchoonoo/HNSCC_Clinical_Data_Notebook/master/parse_clinical_xml.py)\n",
    "* [[Download R script here]](https://raw.githubusercontent.com/gchoonoo/HNSCC_Clinical_Data_Notebook/master/parse_clinical_xml_part2.r)\n",
    "\n",
    "** All code is available on GitHub: [https://github.com/gchoonoo/HNSCC_Clinical_Data_Notebook](https://github.com/gchoonoo/HNSCC_Clinical_Data_Notebook) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Manifest File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigate to the TCGA Data Portal\n",
    "\n",
    "https://portal.gdc.cancer.gov/\n",
    "\n",
    "Click on \"Data\"\n",
    "\n",
    "Select \"Head and Neck\" in the primary site section on the left\n",
    "\n",
    "Select \"Clinical Supplement\" under the File Counts by Data Type widget\n",
    "\n",
    "Click \"Add all files to cart\". Should be 528 files for this timestamp (5/9/17), one XML file for each patient.\n",
    "\n",
    "Click on your cart.\n",
    "\n",
    "Click Download and from the pull down menu select \"Manifest\"\n",
    "\n",
    "This will download a text file containing the cases you would like to query from the GDC Client database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the XML Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the GDC Client\n",
    "\n",
    "https://gdc.cancer.gov/access-data/gdc-data-transfer-tool\n",
    "\n",
    "Run this line of code in terminal to download files (change to your directory with the manifest file):\n",
    "\n",
    "gdc-client download -m  /Users/choonoo/HNSCC_Clinical_Data_Notebook/gdc_manifest_20170509_203418.txt\n",
    "\n",
    "Once these are done downloading, move them into a new folder and you're ready to parse them in python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Python script to parse XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries\n",
    "\"\"\"\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "import os\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set directory where your downloaded files are\n",
    "\"\"\"\n",
    "\n",
    "os.chdir(\"/Users/choonoo/clinical_data_5_9_17\")\n",
    "\n",
    "rootdir = \"/Users/choonoo/clinical_data_5_9_17\"\n",
    "\n",
    "\"\"\"\n",
    "Walk through directory and pull list of all nested files\n",
    "\"\"\"\n",
    "\n",
    "dir_list = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        print os.path.join(subdir, file)\n",
    "        clin_files = os.path.join(subdir, file)\n",
    "        dir_list.append(clin_files)\n",
    "        \n",
    "\"\"\"\n",
    "Extract only the xml files for each patient\n",
    "\"\"\"\n",
    "\n",
    "dir_list2 = [dir_list for dir_list in dir_list if 'parcel' not in dir_list]\n",
    "\n",
    "dir_list3 = [dir_list2 for dir_list2 in dir_list2 if 'xml' in dir_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loop through each XML file and iterate through to extract all nested variables within\n",
    "\"\"\"\n",
    "for i in range(0,len(dir_list3)):\n",
    "    new_list = []      \n",
    "    iter_et = et.iterparse(dir_list3[i], events=['start', 'end'])\n",
    "    event, root = iter_et.next()\n",
    "    for event, element in iter_et:\n",
    "        if event == \"end\" and element.tag != root.tag:\n",
    "            print element.tag + \":\", element.text\n",
    "            result = element.tag + \":\", element.text\n",
    "            new_list.append(result) \n",
    "            element.clear()\n",
    "\n",
    "    root.clear() \n",
    "    \n",
    "\"\"\"\n",
    "Write each parsed XML file to a text file in a new folder\n",
    "\"\"\"    \n",
    "    fh = open(\"/Users/choonoo/clinical_data_5_9_17_parsed/file\" + str(i) + \".txt\", 'w')\n",
    "    w = csv.writer(fh, delimiter='\\t')\n",
    "    w.writerows(new_list[1:])    \n",
    "    fh.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run R script to process text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean NA function\n",
    "clean_na = function(data_set){\n",
    "  \n",
    "  for (i in 1:dim(data_set)[2]){\n",
    "    print(i)\n",
    "    if(sum(na.omit(data_set[,i] == \"\") > 0)){\n",
    "      \n",
    "      data_set[which( data_set[,i] == \"\"),i] <- NA\n",
    "    }\n",
    "    \n",
    "  }\n",
    "  return(data_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set directory where to save parsed data\n",
    "dir_folder = dir(\"clinical_data_5_9_17_parsed\")\n",
    "\n",
    "# save empty vector to save parsed data\n",
    "pat_data <- vector(\"list\",length(dir_folder))\n",
    "\n",
    "# save empty vector to save union of clinical variables\n",
    "pat_data_names <- vector(\"list\",length(dir_folder))\n",
    "\n",
    "# read in the data\n",
    "for(i in 1:length(dir_folder)){\n",
    "  \n",
    "  print(i)\n",
    "  \n",
    "  read.delim(paste(\"clinical_data_5_9_17_parsed\", dir_folder[i],sep=\"/\"), header=F, sep=\"\\t\") -> pat_data[[i]]\n",
    "  \n",
    "  #pat_data_v2 = pat_data[[1]]\n",
    "  \n",
    "  pat_data[[i]][,1] <- gsub(\":\",\"\",sapply(strsplit(as.character(pat_data[[i]][,1]), \"}\"),\"[\",2))\n",
    "  \n",
    "  \n",
    "  \n",
    "  # fix duplicates\n",
    "  if(sum(duplicated(pat_data[[i]][,1])) > 0){\n",
    "    \n",
    "    duplicates = unique(pat_data[[i]][duplicated(pat_data[[i]][,1]),1])\n",
    "    \n",
    "    \n",
    "    for(a in 1:length(duplicates)){\n",
    "      #print(i)\n",
    "      pat_data[[i]][pat_data[[i]][,1] %in% duplicates[a],1] <- paste0(pat_data[[i]][pat_data[[i]][,1] %in% duplicates[a],1], seq(1:length(pat_data[[i]][pat_data[[i]][,1] %in% duplicates[a],1])))\n",
    "      \n",
    "    }\n",
    "    \n",
    "  }\n",
    "  \n",
    "  pat_data_v2 = pat_data[[i]]\n",
    "  \n",
    "  t(pat_data_v2) -> pat_data_v3\n",
    "  \n",
    "  as.data.frame(pat_data_v3) -> pat_data_v3\n",
    "  \n",
    "  names(pat_data_v3) <- pat_data_v2[,1]\n",
    "  \n",
    "  pat_data_v3[-1,] -> pat_data_v4\n",
    "  \n",
    "  print(names(pat_data_v4))\n",
    "  \n",
    "  row.names(pat_data_v4) <- pat_data_v4[,\"bcr_patient_barcode\"]\n",
    "  \n",
    "  pat_data[[i]] <- pat_data_v4\n",
    "  \n",
    "  pat_data_names[[i]] <- names(pat_data_v4)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# match names based on union variables between all files (168 variables in total)\n",
    "\n",
    "unique(unlist(pat_data_names)) -> full_names\n",
    "\n",
    "for(a in 1:length(pat_data)){\n",
    "  \n",
    "  print(a)\n",
    "  \n",
    "  if(sum(!full_names %in% names(pat_data[[a]])) > 0){\n",
    "    \n",
    "    for(i in full_names[!full_names %in% names(pat_data[[a]])]){\n",
    "      \n",
    "      pat_data[[a]][,i] <- NA\n",
    "      \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  pat_data[[a]] <- pat_data[[a]][,full_names]\n",
    "  \n",
    "}\n",
    "\n",
    "# rbind all files\n",
    "clinical_data_full = do.call(rbind,pat_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean \"\\n\" to NA\n",
    "for(i in 1:ncol(clinical_data_full)){\n",
    "  if(length(grep(\"\\n\",clinical_data_full[,i])) > 0){\n",
    "    \n",
    "    if(length(levels(clinical_data_full[,i])) > 0){\n",
    "      levels(clinical_data_full[,i])[grep(\"\\n\", levels(clinical_data_full[,i]))] <- NA\n",
    "      \n",
    "    }else{\n",
    "      clinical_data_full[grep(\"\\n\",clinical_data_full[,i]),i] <- NA\n",
    "    }\n",
    "    \n",
    "  }\n",
    "}\n",
    "\n",
    "# clean blanks to NA\n",
    "clean_na(clinical_data_full) -> clinical_data_full_v2\n",
    "\n",
    "# save clinical data\n",
    "write.table(file=\"clinical_tcga_data_5_9_17.txt\", x=clinical_data_full_v2, sep=\"\\t\", quote=F, row.names=F)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
